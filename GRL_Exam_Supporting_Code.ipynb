{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t62bXRfTY-nJ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and Imports"
      ],
      "metadata": {
        "id": "t62bXRfTY-nJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg-lib torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cu116.html"
      ],
      "metadata": {
        "id": "zlBe_kskZHel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Dropout\n",
        "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n",
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import degree\n",
        "from collections import Counter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch_geometric.datasets as datasets\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "from typing import Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "from torch_geometric.typing import Adj, OptTensor, OptPairTensor, PairTensor, Size\n",
        "from torch_geometric.utils import add_self_loops, remove_self_loops, softmax\n",
        "from torch_geometric.utils import is_sparse, is_torch_sparse_tensor\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "xHtEYO6_Y_vH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get GPU Specification\n",
        "Will be usefull to report the time on current machine"
      ],
      "metadata": {
        "id": "g8Yjo-h2eklo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfrZ5Lk9euZr",
        "outputId": "e1d59d61-f265-4597-8a21-8734ca47c6c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 29 01:24:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets Preparation"
      ],
      "metadata": {
        "id": "44Ezl8reaBsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_info(dataset):\n",
        "  # Print information about the dataset\n",
        "  print(dataset.data)\n",
        "  print(f'Number of graphs: {len(dataset)}')\n",
        "  print(f'Number of nodes: {dataset[0].x.shape[0]}')\n",
        "  print(f'Number of features: {dataset.num_features}')\n",
        "  print(f'Number of classes: {dataset.num_classes}')\n",
        "  print(f'Has isolated nodes: {dataset[0].has_isolated_nodes()}')"
      ],
      "metadata": {
        "id": "9dRWsEE8aMK4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset from PyTorch Geometric\n",
        "dataset_cite_seer = Planetoid(root=\"./\", name=\"CiteSeer\")\n",
        "\n",
        "print(\"CiteSeer dataset:\")\n",
        "get_dataset_info(dataset_cite_seer)\n",
        "print()\n",
        "\n",
        "dataset_cora = Planetoid(\n",
        "    root=\"./\",\n",
        "    name='Cora',\n",
        "    split=\"public\",\n",
        "    transform=torch_geometric.transforms.GCNNorm()\n",
        "  )\n",
        "\n",
        "print(\"Cora dataset:\")\n",
        "get_dataset_info(dataset_cora)\n",
        "print()\n",
        "\n",
        "dataset_pub_med = Planetoid(root=\"./\", name=\"PubMed\")\n",
        "\n",
        "print(\"PubMed dataset:\")\n",
        "get_dataset_info(dataset_pub_med)\n",
        "print()"
      ],
      "metadata": {
        "id": "XIyBzg-qaEJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cite_seer = dataset_cite_seer[0]\n",
        "data_cora = dataset_cora[0]\n",
        "data_pub_med = dataset_pub_med[0]"
      ],
      "metadata": {
        "id": "I3-c7N76eGuK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architectures"
      ],
      "metadata": {
        "id": "XxNWMDCTbyml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN: Graph Convolutional Network"
      ],
      "metadata": {
        "id": "nMMiltCacxBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "  \"\"\"Graph Convolutional Network\"\"\"\n",
        "  def __init__(self, dim_in, dim_h, dim_out):\n",
        "    super().__init__()\n",
        "    self.gcn1 = GCNConv(dim_in, dim_h)\n",
        "    self.gcn2 = GCNConv(dim_h, dim_out)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    h = self.gcn1(x, edge_index)\n",
        "    h = torch.relu(h)\n",
        "    h = F.dropout(h, p=0.5, training=self.training)\n",
        "    h = self.gcn2(h, edge_index)\n",
        "    return h, F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "AT9BDh_Jb0aq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom GCN Implementation"
      ],
      "metadata": {
        "id": "aAUIiy-Yc2Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNConvMy(nn.Module):\n",
        "    \"\"\"Custom GCN Layer Implementation\"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "      super(GCNConvMy, self).__init__()\n",
        "\n",
        "      self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
        "      torch.nn.init.xavier_uniform(self.W)\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "      neighs = adj_matrix.sum(0)\n",
        "      res = torch.mm(torch.mm(adj_matrix, x), self.W)\n",
        "      res = torch.div(res.T, neighs).T\n",
        "\n",
        "      return res"
      ],
      "metadata": {
        "id": "-lNn_RHUb8Fu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNMy(torch.nn.Module):\n",
        "  \"\"\"Graph Convolutional Network With Custom Layer Implementation\"\"\"\n",
        "  def __init__(self, dim_in, dim_h, dim_out):\n",
        "    super().__init__()\n",
        "    self.gcn1 = GCNConvMy(dim_in, dim_h)\n",
        "    self.gcn2 = GCNConvMy(dim_h, dim_out)\n",
        "   \n",
        "  def forward(self, x, adj_matrix):\n",
        "    h = self.gcn1(x, adj_matrix)\n",
        "    h = torch.relu(h)\n",
        "    h = F.dropout(h, p=0.5, training=self.training)\n",
        "    h = self.gcn2(h, adj_matrix)\n",
        "    return h, F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "Nn_rMWADbPCu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT: Graph Attention Network"
      ],
      "metadata": {
        "id": "nX8iii800lcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(torch.nn.Module):\n",
        "  \"\"\"Graph Attention Network\"\"\"\n",
        "  def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
        "    super().__init__()\n",
        "    self.gat1 = GATConv(dim_in, dim_h, heads=heads)\n",
        "    self.gat2 = GATConv(dim_h*heads, dim_out, heads=1)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    h = self.gat1(x, edge_index)\n",
        "    h = F.elu(h)\n",
        "    h = F.dropout(h, p=0.6, training=self.training)\n",
        "    h = self.gat2(h, edge_index)\n",
        "    return h, F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "6kvxkXrf0oEN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GATv2: Graph Attention Network"
      ],
      "metadata": {
        "id": "AZHkXiAG0Wv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GATv2(torch.nn.Module):\n",
        "  \"\"\"Graph Attention Network v2\"\"\"\n",
        "  def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
        "    super().__init__()\n",
        "    self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)\n",
        "    self.gat2 = GATv2Conv(dim_h*heads, dim_out, heads=1)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    h = self.gat1(x, edge_index)\n",
        "    h = F.elu(h)\n",
        "    h = F.dropout(h, p=0.6, training=self.training)\n",
        "    h = self.gat2(h, edge_index)\n",
        "    return h, F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "UNfMdb7b0cp8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN + GAT: Use different layers in the network"
      ],
      "metadata": {
        "id": "jmKpZtkbWjPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_GAT(torch.nn.Module):\n",
        "  def __init__(self, dim_in, dim_h, dim_out):\n",
        "    super().__init__()\n",
        "    self.gcn1 = GCNConv(dim_in, dim_h)\n",
        "    self.gat2 = GATConv(dim_h, dim_out, heads=1)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    h = self.gcn1(x, edge_index)\n",
        "    h = torch.relu(h)\n",
        "    h = F.dropout(h, p=0.5, training=self.training)\n",
        "    h = self.gat2(h, edge_index)\n",
        "    return h, F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "hMpEh3ekWpVS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT + GCN: Use different layers in the network"
      ],
      "metadata": {
        "id": "gWoO5VE4ZlzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT_GCN(torch.nn.Module):\n",
        "  def __init__(self, dim_in, dim_h, dim_out, heads=8):\n",
        "    super().__init__()\n",
        "    self.gat1 = GATConv(dim_in, dim_h, heads=heads)\n",
        "    self.gcn2 = GCNConv(dim_h*heads, dim_out)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    h = self.gat1(x, edge_index)\n",
        "    h = F.elu(h)\n",
        "    h = F.dropout(h, p=0.6, training=self.training)\n",
        "    h = self.gcn2(h, edge_index)\n",
        "    return h, F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "6Mg-IsVMZpp2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom L-CAT Implementation"
      ],
      "metadata": {
        "id": "PMgVgMHLc6fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LCATLayerMy(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: Union[int, Tuple[int, int]],\n",
        "        out_channels: int,\n",
        "        heads: int = 1,\n",
        "        concat: bool = True,\n",
        "        negative_slope: float = 0.2,\n",
        "        dropout: float = 0.0,\n",
        "        add_self_loops: bool = True,\n",
        "        edge_dim: Optional[int] = None,\n",
        "        fill_value: Union[float, Tensor, str] = 'mean',\n",
        "        bias: bool = True,\n",
        "        lambda1: Optional[Parameter] = None,\n",
        "        lambda2: Optional[Parameter] = None,\n",
        "        scaling_coef: Optional[int] = None,\n",
        "        add_lambda_constraint: bool = True,\n",
        "        hardcoded_lambdas: Optional[Tuple[int, int]] = None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = heads\n",
        "        self.concat = concat\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "        self.add_self_loops = add_self_loops\n",
        "        self.edge_dim = edge_dim\n",
        "        self.fill_value = fill_value\n",
        "        # The learnable parameters lambda1 and lambda2 for L-CAT modelwise\n",
        "        self.lambda1 = lambda1\n",
        "        self.lambda2 = lambda2\n",
        "        self.scaling_coef = scaling_coef if scaling_coef else 1\n",
        "        if add_lambda_constraint:\n",
        "          self.constraint = torch.sigmoid\n",
        "        else:\n",
        "          self.constraint = None\n",
        "        self.hardcoded_lambdas = hardcoded_lambdas\n",
        "        if hardcoded_lambdas:\n",
        "          self.scaling_coef = 1\n",
        "        \n",
        "\n",
        "        if isinstance(in_channels, int):\n",
        "            self.lin_src = Linear(in_channels, heads * out_channels,\n",
        "                                  bias=False, weight_initializer='glorot')\n",
        "            self.lin_dst = self.lin_src\n",
        "        else:\n",
        "            self.lin_src = Linear(in_channels[0], heads * out_channels, False,\n",
        "                                  weight_initializer='glorot')\n",
        "            self.lin_dst = Linear(in_channels[1], heads * out_channels, False,\n",
        "                                  weight_initializer='glorot')\n",
        "\n",
        "        # The learnable parameters to compute attention coefficients:\n",
        "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
        "\n",
        "        if self.lambda1 == None:\n",
        "          if self.hardcoded_lambdas:\n",
        "            self.lambda1 = torch.tensor(self.hardcoded_lambdas[0])\n",
        "          else:\n",
        "            # The learnable parameter lambda1 for L-CAT layerwise\n",
        "            self.lambda1 = Parameter(torch.Tensor(1))\n",
        "        if self.lambda2 == None:\n",
        "          if self.hardcoded_lambdas:\n",
        "            self.lambda2 = torch.tensor(self.hardcoded_lambdas[1])\n",
        "          else:\n",
        "            # The learnable parameter lambda2 for L-CAT layerwise\n",
        "            self.lambda2 = Parameter(torch.Tensor(1))\n",
        "\n",
        "        # also tried to add xavier_uniform initialization, better without it\n",
        "        # torch.nn.init.xavier_uniform(self.lambda1)\n",
        "        # torch.nn.init.xavier_uniform(self.lambda2)\n",
        "\n",
        "        self.lin_edge = None\n",
        "        self.register_parameter('att_edge', None)\n",
        "\n",
        "        self.bias = Parameter(torch.Tensor(heads * out_channels))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, size: Size = None,\n",
        "                return_attention_weights=None, adj_matrix=None):\n",
        "\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        neighs = adj_matrix.sum(0)\n",
        "        sum_of_neighs_embeds = torch.mm(adj_matrix, x)\n",
        "\n",
        "        # add constraint to lambda2\n",
        "        if self.constraint:\n",
        "          lambda2_constrained = self.constraint(self.lambda2 * self.scaling_coef)\n",
        "        else:\n",
        "          lambda2_constrained = self.lambda2\n",
        "\n",
        "        x = torch.div((x + lambda2_constrained * sum_of_neighs_embeds).T, 1 + lambda2_constrained * neighs).T\n",
        "\n",
        "        # We first transform the input node features\n",
        "        x_src = x_dst = self.lin_src(x).view(-1, H, C)\n",
        "        x = (x_src, x_dst)\n",
        "\n",
        "        # Next, we compute node-level attention coefficients, both for source\n",
        "        # and target nodes (if present):\n",
        "        alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
        "        alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)\n",
        "        alpha = (alpha_src, alpha_dst)\n",
        "\n",
        "        num_nodes = x_src.size(0)\n",
        "        if x_dst is not None:\n",
        "            num_nodes = min(num_nodes, x_dst.size(0))\n",
        "        num_nodes = min(size) if size is not None else num_nodes\n",
        "        edge_index, edge_attr = remove_self_loops(\n",
        "            edge_index, edge_attr)\n",
        "        edge_index, edge_attr = add_self_loops(\n",
        "            edge_index, edge_attr, fill_value=self.fill_value,\n",
        "            num_nodes=num_nodes)\n",
        "\n",
        "        alpha = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr)\n",
        "\n",
        "        out = self.propagate(edge_index, x=x, alpha=alpha, size=size)\n",
        "        out = out.view(-1, self.heads * self.out_channels)\n",
        "        out = out + self.bias\n",
        "\n",
        "        return out, (edge_index, alpha)\n",
        "\n",
        "    def edge_update(self, alpha_j: Tensor, alpha_i: OptTensor,\n",
        "                    edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                    size_i: Optional[int]) -> Tensor:\n",
        "        # Given edge-level attention coefficients for source and target nodes,\n",
        "        # we simply need to sum them up to \"emulate\" concatenation:\n",
        "        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
        "\n",
        "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
        "        \n",
        "        # add constraint to lambda1\n",
        "        if self.constraint:\n",
        "          lambda1_constrained = self.constraint(self.lambda1 * self.scaling_coef)\n",
        "        else:\n",
        "          lambda1_constrained = self.lambda1\n",
        "\n",
        "        alpha = lambda1_constrained * alpha\n",
        "\n",
        "        alpha = softmax(alpha, index, ptr, size_i)\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "\n",
        "        return alpha\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_src.reset_parameters()\n",
        "        self.lin_dst.reset_parameters()\n",
        "        if self.lin_edge is not None:\n",
        "            self.lin_edge.reset_parameters()\n",
        "        glorot(self.att_src)\n",
        "        glorot(self.att_dst)\n",
        "        glorot(self.att_edge)\n",
        "        zeros(self.bias)\n",
        "\n",
        "    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n",
        "        return alpha.unsqueeze(-1) * x_j\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ],
      "metadata": {
        "id": "KwFvtHTpF2pd"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LCATMy(torch.nn.Module):\n",
        "  \"\"\"Learnable Convolutional Attention Layer\"\"\"\n",
        "  def __init__(self, dim_in, dim_h, dim_out, heads=8, hardcoded_lambdas=None, global_lambdas=False):\n",
        "    super().__init__()\n",
        "    if global_lambdas:\n",
        "      self.lambda1 = Parameter(torch.Tensor(1))\n",
        "      self.lambda2 = Parameter(torch.Tensor(1))\n",
        "\n",
        "      self.gat1 = LCATLayerMy(dim_in, dim_h, heads=heads, lambda1=self.lambda1, lambda2=self.lambda2)\n",
        "      self.gat2 = LCATLayerMy(dim_h*heads, dim_out, heads=1, lambda1=self.lambda1, lambda2=self.lambda2)\n",
        "    else:\n",
        "      self.gat1 = LCATLayerMy(dim_in, dim_h, heads=heads, hardcoded_lambdas=hardcoded_lambdas)\n",
        "      self.gat2 = LCATLayerMy(dim_h*heads, dim_out, heads=1, hardcoded_lambdas=hardcoded_lambdas)\n",
        "\n",
        "  def forward(self, x, edge_index, adj_matrix):\n",
        "    h, weights = self.gat1(x, edge_index, return_attention_weights=True, adj_matrix=adj_matrix)\n",
        "    h = F.elu(h)\n",
        "    h = F.dropout(h, p=0.6, training=self.training)\n",
        "    h, weights = self.gat2(h, edge_index, return_attention_weights=True, adj_matrix=adj_matrix)\n",
        "    return h, F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "xLd7R9ct6L26"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities, Support Classes and Experimental Setup"
      ],
      "metadata": {
        "id": "dPCnFXOKhXyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(pred, y):\n",
        "    return ((pred == y).sum() / len(y)).item()\n",
        "\n",
        "class Trainer:\n",
        "  \"\"\"Utility Class to handle the training pocedure\"\"\"\n",
        "  def __init__(self, config):\n",
        "    self.criterion = config[\"loss\"] \n",
        "    self.optimizer = config[\"optimizer\"]\n",
        "    self.lr = config[\"learning_rate\"]\n",
        "    self.weight_decay = config[\"weight_decay\"]\n",
        "    self.epochs = config[\"num_epochs\"] \n",
        "    self.report_freq = config[\"report_freq\"]\n",
        "    self.data_requirements = (config[\"req_edge_index\"], config[\"req_adj_matrix\"])\n",
        "    self.training_time = None\n",
        "\n",
        "  def train(self, model, data):\n",
        "    optimizer = self.optimizer(model.parameters(),\n",
        "                                      lr=self.lr,\n",
        "                                      weight_decay=self.weight_decay)\n",
        "    forward_input = [data.x]\n",
        "\n",
        "    if self.data_requirements[0]:\n",
        "      forward_input.append(data.edge_index)\n",
        "\n",
        "    if self.data_requirements[1]:\n",
        "      adj_matrix = torch_geometric.utils.to_dense_adj(data.edge_index).squeeze(0)\n",
        "      adj_matrix = adj_matrix + torch.eye(adj_matrix.shape[0]) # added self-loop\n",
        "\n",
        "      forward_input.append(adj_matrix)\n",
        "\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    for epoch in range(self.epochs):\n",
        "        optimizer.zero_grad()\n",
        "        _, out = model(*forward_input)\n",
        "        loss = self.criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "        acc = calculate_accuracy(out[data.train_mask].argmax(dim=1), data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        val_loss = self.criterion(out[data.val_mask], data.y[data.val_mask])\n",
        "        val_acc = calculate_accuracy(out[data.val_mask].argmax(dim=1), data.y[data.val_mask])\n",
        "\n",
        "        if(epoch % self.report_freq == 0):\n",
        "            print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc: '\n",
        "                  f'{acc*100:>6.2f}% | Val Loss: {val_loss:.2f} | '\n",
        "                  f'Val Acc: {val_acc*100:.2f}%')\n",
        "          \n",
        "    end = time.time()\n",
        "    self.training_time = end - start\n",
        "\n",
        "    return model\n",
        "\n",
        "  def print_training_time(self):\n",
        "    print('Training took {:.2f}s'.format(self.training_time))\n",
        "\n",
        "\n",
        "class Tester:\n",
        "  \"\"\"Utility Class to handle the testing pocedure\"\"\"\n",
        "  def __init__(self, config):\n",
        "    self.data_requirements = (config[\"req_edge_index\"], config[\"req_adj_matrix\"])\n",
        "    self.testing_time = None\n",
        "\n",
        "  def test(self, model, data):\n",
        "    \"\"\"Evaluate the model on test set and print the accuracy score.\"\"\"\n",
        "    forward_input = [data.x]\n",
        "\n",
        "    if self.data_requirements[0]:\n",
        "      forward_input.append(data.edge_index)\n",
        "\n",
        "    if self.data_requirements[1]:\n",
        "      adj_matrix = torch_geometric.utils.to_dense_adj(data.edge_index).squeeze(0)\n",
        "      adj_matrix = adj_matrix + torch.eye(adj_matrix.shape[0]) # added self-loop\n",
        "\n",
        "      forward_input.append(adj_matrix)\n",
        "\n",
        "    start = time.time()\n",
        "    model.eval()\n",
        "    _, out = model(*forward_input)\n",
        "    acc = calculate_accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
        "    end = time.time()\n",
        "    self.testing_time = end - start\n",
        "\n",
        "    return acc\n",
        "\n",
        "  def print_testing_time(self):\n",
        "    print('Testing took {:.2f}s'.format(self.testing_time))"
      ],
      "metadata": {
        "id": "YVE9_ma7hOaY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment:\n",
        "  \"\"\"Utility Class to setup and run the exact experiment\"\"\"\n",
        "  def __init__(self, data, model_type, config):\n",
        "    self.model_name = config[\"model_name\"]\n",
        "    self.dataset_name = config[\"dataset_name\"]\n",
        "    if \"num_heads\" in config.keys():\n",
        "      if \"hardcoded_lambdas\" in config.keys():\n",
        "        self.model = model_type(config[\"input_dimension\"], config[\"hidden_dimension\"], \n",
        "                                config[\"output_dimension\"], hardcoded_lambdas=config[\"hardcoded_lambdas\"], \n",
        "                                global_lambdas=config[\"global_lambdas\"] if \"global_lambdas\" in config.keys() else None)        \n",
        "      else:\n",
        "        if \"global_lambdas\" in config.keys():\n",
        "          self.model = model_type(config[\"input_dimension\"], config[\"hidden_dimension\"], \n",
        "                                          config[\"output_dimension\"], heads=config[\"num_heads\"],\n",
        "                                          global_lambdas=config[\"global_lambdas\"])\n",
        "        else:\n",
        "          self.model = model_type(config[\"input_dimension\"], config[\"hidden_dimension\"], \n",
        "                                  config[\"output_dimension\"], heads=config[\"num_heads\"])\n",
        "    else:\n",
        "      self.model = model_type(config[\"input_dimension\"], config[\"hidden_dimension\"], config[\"output_dimension\"])\n",
        "    self.trainer = Trainer(config)\n",
        "    self.tester = Tester(config)\n",
        "    self.data = data\n",
        "\n",
        "    print(f\"Finished experiment initialization (model: {self.model_name}, dataset: {self.dataset_name}).\")\n",
        "    print(self.model)\n",
        "\n",
        "  def run(self):\n",
        "    print(\"Started model training.\")\n",
        "    self.model = self.trainer.train(self.model, self.data)\n",
        "    print(\"Finished model training.\")\n",
        "\n",
        "    print(\"Started model testing.\")\n",
        "    test_acc = self.tester.test(self.model, self.data)\n",
        "    print(\"Finished model testing.\")\n",
        "\n",
        "    self.print_experiment_report(test_acc)\n",
        "\n",
        "    return test_acc, self.trainer.training_time, self.tester.testing_time\n",
        "\n",
        "  def print_experiment_report(self, accuracy):\n",
        "    self.trainer.print_training_time()\n",
        "    self.tester.print_testing_time()\n",
        "    print(f'{self.model_name} test accuracy: {accuracy*100:.2f}%\\n')"
      ],
      "metadata": {
        "id": "e1SDhlwjfC7z"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ],
      "metadata": {
        "id": "--mpNOIvuGT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN Experiments"
      ],
      "metadata": {
        "id": "H3if0L1buIb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "MNTDL9RwuN_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_cite_seer_config = {\n",
        "    \"model_name\": \"GCN\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gcn_cite_seer = Experiment(data_cite_seer, GCN, gcn_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time =experiment_gcn_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbvvMPqQpkOw",
        "outputId": "c6b37d54-3b58-44ae-db77-f8a7c463a372"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GCN, dataset: CiteSeer).\n",
            "GCN(\n",
            "  (gcn1): GCNConv(3703, 16)\n",
            "  (gcn2): GCNConv(16, 6)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.792 | Train Acc:  15.83% | Val Loss: 1.79 | Val Acc: 14.20%\n",
            "Epoch  10 | Train Loss: 0.365 | Train Acc:  92.50% | Val Loss: 1.25 | Val Acc: 57.20%\n",
            "Epoch  20 | Train Loss: 0.107 | Train Acc:  96.67% | Val Loss: 1.34 | Val Acc: 56.40%\n",
            "Epoch  30 | Train Loss: 0.069 | Train Acc:  98.33% | Val Loss: 1.60 | Val Acc: 54.80%\n",
            "Epoch  40 | Train Loss: 0.019 | Train Acc: 100.00% | Val Loss: 1.54 | Val Acc: 56.80%\n",
            "Epoch  50 | Train Loss: 0.030 | Train Acc: 100.00% | Val Loss: 1.66 | Val Acc: 56.20%\n",
            "Epoch  60 | Train Loss: 0.037 | Train Acc:  99.17% | Val Loss: 1.47 | Val Acc: 57.80%\n",
            "Epoch  70 | Train Loss: 0.042 | Train Acc:  99.17% | Val Loss: 1.44 | Val Acc: 58.60%\n",
            "Epoch  80 | Train Loss: 0.037 | Train Acc: 100.00% | Val Loss: 1.48 | Val Acc: 59.60%\n",
            "Epoch  90 | Train Loss: 0.024 | Train Acc: 100.00% | Val Loss: 1.36 | Val Acc: 61.40%\n",
            "Epoch 100 | Train Loss: 0.040 | Train Acc: 100.00% | Val Loss: 1.44 | Val Acc: 60.00%\n",
            "Epoch 110 | Train Loss: 0.045 | Train Acc:  99.17% | Val Loss: 1.42 | Val Acc: 61.00%\n",
            "Epoch 120 | Train Loss: 0.028 | Train Acc: 100.00% | Val Loss: 1.36 | Val Acc: 62.20%\n",
            "Epoch 130 | Train Loss: 0.035 | Train Acc: 100.00% | Val Loss: 1.49 | Val Acc: 60.40%\n",
            "Epoch 140 | Train Loss: 0.049 | Train Acc:  99.17% | Val Loss: 1.51 | Val Acc: 62.40%\n",
            "Epoch 150 | Train Loss: 0.048 | Train Acc:  99.17% | Val Loss: 1.52 | Val Acc: 59.00%\n",
            "Epoch 160 | Train Loss: 0.032 | Train Acc: 100.00% | Val Loss: 1.45 | Val Acc: 60.60%\n",
            "Epoch 170 | Train Loss: 0.026 | Train Acc: 100.00% | Val Loss: 1.45 | Val Acc: 62.60%\n",
            "Epoch 180 | Train Loss: 0.047 | Train Acc: 100.00% | Val Loss: 1.47 | Val Acc: 61.40%\n",
            "Epoch 190 | Train Loss: 0.029 | Train Acc:  99.17% | Val Loss: 1.41 | Val Acc: 63.80%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 6.25s\n",
            "Testing took 0.01s\n",
            "GCN test accuracy: 67.70%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "YWShRF7ZuTDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_cora_config = {\n",
        "    \"model_name\": \"GCN\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gcn_cora = Experiment(data_cora, GCN, gcn_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgOJmR6HuVGj",
        "outputId": "bbd19ded-591c-4bc4-ad5a-6db1730e9bf3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GCN, dataset: Cora).\n",
            "GCN(\n",
            "  (gcn1): GCNConv(1433, 16)\n",
            "  (gcn2): GCNConv(16, 7)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.956 | Train Acc:  12.14% | Val Loss: 1.96 | Val Acc: 10.40%\n",
            "Epoch  10 | Train Loss: 0.786 | Train Acc:  87.86% | Val Loss: 1.29 | Val Acc: 65.80%\n",
            "Epoch  20 | Train Loss: 0.306 | Train Acc:  95.00% | Val Loss: 1.06 | Val Acc: 67.80%\n",
            "Epoch  30 | Train Loss: 0.167 | Train Acc:  96.43% | Val Loss: 1.05 | Val Acc: 69.60%\n",
            "Epoch  40 | Train Loss: 0.076 | Train Acc:  99.29% | Val Loss: 1.07 | Val Acc: 70.40%\n",
            "Epoch  50 | Train Loss: 0.100 | Train Acc:  97.14% | Val Loss: 1.05 | Val Acc: 70.20%\n",
            "Epoch  60 | Train Loss: 0.066 | Train Acc:  99.29% | Val Loss: 1.08 | Val Acc: 70.20%\n",
            "Epoch  70 | Train Loss: 0.048 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 70.00%\n",
            "Epoch  80 | Train Loss: 0.046 | Train Acc: 100.00% | Val Loss: 1.00 | Val Acc: 71.20%\n",
            "Epoch  90 | Train Loss: 0.053 | Train Acc:  99.29% | Val Loss: 1.12 | Val Acc: 68.40%\n",
            "Epoch 100 | Train Loss: 0.040 | Train Acc: 100.00% | Val Loss: 1.09 | Val Acc: 74.00%\n",
            "Epoch 110 | Train Loss: 0.048 | Train Acc: 100.00% | Val Loss: 1.13 | Val Acc: 69.60%\n",
            "Epoch 120 | Train Loss: 0.049 | Train Acc: 100.00% | Val Loss: 1.03 | Val Acc: 69.60%\n",
            "Epoch 130 | Train Loss: 0.047 | Train Acc:  99.29% | Val Loss: 1.12 | Val Acc: 70.80%\n",
            "Epoch 140 | Train Loss: 0.062 | Train Acc:  99.29% | Val Loss: 1.01 | Val Acc: 70.40%\n",
            "Epoch 150 | Train Loss: 0.034 | Train Acc: 100.00% | Val Loss: 1.03 | Val Acc: 71.20%\n",
            "Epoch 160 | Train Loss: 0.045 | Train Acc:  99.29% | Val Loss: 1.06 | Val Acc: 72.60%\n",
            "Epoch 170 | Train Loss: 0.048 | Train Acc:  98.57% | Val Loss: 1.17 | Val Acc: 70.20%\n",
            "Epoch 180 | Train Loss: 0.053 | Train Acc:  99.29% | Val Loss: 1.13 | Val Acc: 71.60%\n",
            "Epoch 190 | Train Loss: 0.035 | Train Acc:  99.29% | Val Loss: 1.00 | Val Acc: 71.80%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 5.70s\n",
            "Testing took 0.01s\n",
            "GCN test accuracy: 77.90%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "r89qwvJRxcFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_pub_med_config = {\n",
        "    \"model_name\": \"GCN\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gcn_pub_med = Experiment(data_pub_med, GCN, gcn_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdcC3WmFxdni",
        "outputId": "de1a62e1-cae8-4590-a6f1-7e190269de34"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GCN, dataset: PubMed).\n",
            "GCN(\n",
            "  (gcn1): GCNConv(500, 16)\n",
            "  (gcn2): GCNConv(16, 3)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.098 | Train Acc:  31.67% | Val Loss: 1.10 | Val Acc: 33.20%\n",
            "Epoch  10 | Train Loss: 0.948 | Train Acc:  83.33% | Val Loss: 1.01 | Val Acc: 67.00%\n",
            "Epoch  20 | Train Loss: 0.755 | Train Acc:  85.00% | Val Loss: 0.89 | Val Acc: 71.00%\n",
            "Epoch  30 | Train Loss: 0.503 | Train Acc:  95.00% | Val Loss: 0.78 | Val Acc: 70.60%\n",
            "Epoch  40 | Train Loss: 0.425 | Train Acc:  93.33% | Val Loss: 0.70 | Val Acc: 73.40%\n",
            "Epoch  50 | Train Loss: 0.339 | Train Acc:  93.33% | Val Loss: 0.67 | Val Acc: 72.00%\n",
            "Epoch  60 | Train Loss: 0.301 | Train Acc:  95.00% | Val Loss: 0.65 | Val Acc: 73.80%\n",
            "Epoch  70 | Train Loss: 0.161 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 74.40%\n",
            "Epoch  80 | Train Loss: 0.174 | Train Acc:  96.67% | Val Loss: 0.64 | Val Acc: 74.60%\n",
            "Epoch  90 | Train Loss: 0.166 | Train Acc:  96.67% | Val Loss: 0.65 | Val Acc: 73.20%\n",
            "Epoch 100 | Train Loss: 0.140 | Train Acc: 100.00% | Val Loss: 0.65 | Val Acc: 74.20%\n",
            "Epoch 110 | Train Loss: 0.137 | Train Acc:  98.33% | Val Loss: 0.64 | Val Acc: 73.20%\n",
            "Epoch 120 | Train Loss: 0.122 | Train Acc: 100.00% | Val Loss: 0.64 | Val Acc: 75.00%\n",
            "Epoch 130 | Train Loss: 0.193 | Train Acc:  96.67% | Val Loss: 0.62 | Val Acc: 75.60%\n",
            "Epoch 140 | Train Loss: 0.124 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 76.60%\n",
            "Epoch 150 | Train Loss: 0.124 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 77.60%\n",
            "Epoch 160 | Train Loss: 0.129 | Train Acc: 100.00% | Val Loss: 0.64 | Val Acc: 74.80%\n",
            "Epoch 170 | Train Loss: 0.114 | Train Acc:  98.33% | Val Loss: 0.60 | Val Acc: 75.20%\n",
            "Epoch 180 | Train Loss: 0.095 | Train Acc: 100.00% | Val Loss: 0.67 | Val Acc: 74.80%\n",
            "Epoch 190 | Train Loss: 0.102 | Train Acc: 100.00% | Val Loss: 0.70 | Val Acc: 72.80%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 21.20s\n",
            "Testing took 0.03s\n",
            "GCN test accuracy: 78.40%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom GCN Experiments"
      ],
      "metadata": {
        "id": "4K9YTEl6x6xm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "WAPxBcZNyRb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_gcn_cite_seer_config = {\n",
        "    \"model_name\": \"GCNMy\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": False,\n",
        "    \"req_adj_matrix\": True\n",
        "}\n",
        "\n",
        "experiment_gcn_my_cite_seer = Experiment(data_cite_seer, GCNMy, custom_gcn_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_my_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kzcr7lkyT50",
        "outputId": "e5942fef-d61f-41c2-ee98-a62fe1183b87"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-d65b2ecb5a80>:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(self.W)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GCNMy, dataset: CiteSeer).\n",
            "GCNMy(\n",
            "  (gcn1): GCNConvMy()\n",
            "  (gcn2): GCNConvMy()\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.798 | Train Acc:  16.67% | Val Loss: 1.79 | Val Acc: 15.20%\n",
            "Epoch  10 | Train Loss: 0.505 | Train Acc:  89.17% | Val Loss: 1.26 | Val Acc: 56.20%\n",
            "Epoch  20 | Train Loss: 0.167 | Train Acc:  95.83% | Val Loss: 1.33 | Val Acc: 59.00%\n",
            "Epoch  30 | Train Loss: 0.127 | Train Acc:  95.00% | Val Loss: 1.43 | Val Acc: 58.80%\n",
            "Epoch  40 | Train Loss: 0.077 | Train Acc:  99.17% | Val Loss: 1.39 | Val Acc: 59.40%\n",
            "Epoch  50 | Train Loss: 0.067 | Train Acc:  98.33% | Val Loss: 1.56 | Val Acc: 60.00%\n",
            "Epoch  60 | Train Loss: 0.047 | Train Acc:  99.17% | Val Loss: 1.48 | Val Acc: 60.20%\n",
            "Epoch  70 | Train Loss: 0.062 | Train Acc:  98.33% | Val Loss: 1.56 | Val Acc: 60.20%\n",
            "Epoch  80 | Train Loss: 0.033 | Train Acc: 100.00% | Val Loss: 1.47 | Val Acc: 61.20%\n",
            "Epoch  90 | Train Loss: 0.055 | Train Acc:  98.33% | Val Loss: 1.57 | Val Acc: 58.60%\n",
            "Epoch 100 | Train Loss: 0.040 | Train Acc: 100.00% | Val Loss: 1.47 | Val Acc: 61.20%\n",
            "Epoch 110 | Train Loss: 0.042 | Train Acc: 100.00% | Val Loss: 1.41 | Val Acc: 59.40%\n",
            "Epoch 120 | Train Loss: 0.062 | Train Acc:  97.50% | Val Loss: 1.48 | Val Acc: 59.40%\n",
            "Epoch 130 | Train Loss: 0.067 | Train Acc:  97.50% | Val Loss: 1.45 | Val Acc: 62.80%\n",
            "Epoch 140 | Train Loss: 0.041 | Train Acc:  99.17% | Val Loss: 1.54 | Val Acc: 61.20%\n",
            "Epoch 150 | Train Loss: 0.042 | Train Acc:  99.17% | Val Loss: 1.59 | Val Acc: 60.60%\n",
            "Epoch 160 | Train Loss: 0.030 | Train Acc:  99.17% | Val Loss: 1.54 | Val Acc: 63.00%\n",
            "Epoch 170 | Train Loss: 0.026 | Train Acc: 100.00% | Val Loss: 1.68 | Val Acc: 58.80%\n",
            "Epoch 180 | Train Loss: 0.039 | Train Acc:  98.33% | Val Loss: 1.62 | Val Acc: 58.80%\n",
            "Epoch 190 | Train Loss: 0.038 | Train Acc:  99.17% | Val Loss: 1.53 | Val Acc: 60.80%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 244.91s\n",
            "Testing took 1.02s\n",
            "GCNMy test accuracy: 67.90%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "x-2hBk4MzE0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_gcn_cora_config = {\n",
        "    \"model_name\": \"GCNMy\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": False,\n",
        "    \"req_adj_matrix\": True\n",
        "}\n",
        "\n",
        "experiment_gcn_my_cora = Experiment(data_cora, GCNMy, custom_gcn_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_my_cora.run()"
      ],
      "metadata": {
        "id": "ucvfR8x4zGXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "FO1VQ4sfzHVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_gcn_pub_med_config = {\n",
        "    \"model_name\": \"GCNMy\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": False,\n",
        "    \"req_adj_matrix\": True\n",
        "}\n",
        "\n",
        "experiment_gcn_my_pub_med = Experiment(data_pub_med, GCNMy, custom_gcn_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_my_pub_med.run()"
      ],
      "metadata": {
        "id": "u5wGo7QozJF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT Experiments"
      ],
      "metadata": {
        "id": "Mr9a7T4j2f6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "UIpSWyOJ2kOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gat_cite_seer_config = {\n",
        "    \"model_name\": \"GAT\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gat_cite_seer = Experiment(data_cite_seer, GAT, gat_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gat_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4gXkpA52jh2",
        "outputId": "f85abcb3-0a23-469a-b486-9e3da0ccc6ad"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GAT, dataset: CiteSeer).\n",
            "GAT(\n",
            "  (gat1): GATv2Conv(3703, 16, heads=8)\n",
            "  (gat2): GATv2Conv(128, 6, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.805 | Train Acc:  15.00% | Val Loss: 1.82 | Val Acc: 17.00%\n",
            "Epoch  10 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.37 | Val Acc: 64.00%\n",
            "Epoch  20 | Train Loss: 0.000 | Train Acc: 100.00% | Val Loss: 1.66 | Val Acc: 63.20%\n",
            "Epoch  30 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 1.53 | Val Acc: 62.80%\n",
            "Epoch  40 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.26 | Val Acc: 67.20%\n",
            "Epoch  50 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 68.60%\n",
            "Epoch  60 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.12 | Val Acc: 67.80%\n",
            "Epoch  70 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.13 | Val Acc: 67.40%\n",
            "Epoch  80 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 67.20%\n",
            "Epoch  90 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.09 | Val Acc: 67.60%\n",
            "Epoch 100 | Train Loss: 0.014 | Train Acc:  99.17% | Val Loss: 1.18 | Val Acc: 66.40%\n",
            "Epoch 110 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.13 | Val Acc: 68.40%\n",
            "Epoch 120 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 67.80%\n",
            "Epoch 130 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.17 | Val Acc: 67.20%\n",
            "Epoch 140 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 1.15 | Val Acc: 68.20%\n",
            "Epoch 150 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.18 | Val Acc: 67.20%\n",
            "Epoch 160 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.13 | Val Acc: 68.20%\n",
            "Epoch 170 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 67.40%\n",
            "Epoch 180 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.22 | Val Acc: 68.00%\n",
            "Epoch 190 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.32 | Val Acc: 66.60%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 60.57s\n",
            "Testing took 0.12s\n",
            "GAT test accuracy: 65.90%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "6VqBXC5v2olh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gat_cora_config = {\n",
        "    \"model_name\": \"GAT\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gat_cora = Experiment(data_cora, GAT, gat_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gat_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY-DkUx7yohg",
        "outputId": "2319424d-2a83-435c-d663-101d420966ad"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GAT, dataset: Cora).\n",
            "GAT(\n",
            "  (gat1): GATv2Conv(1433, 16, heads=8)\n",
            "  (gat2): GATv2Conv(128, 7, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.959 | Train Acc:  14.29% | Val Loss: 1.97 | Val Acc: 13.80%\n",
            "Epoch  10 | Train Loss: 0.018 | Train Acc: 100.00% | Val Loss: 0.70 | Val Acc: 79.00%\n",
            "Epoch  20 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 0.97 | Val Acc: 75.60%\n",
            "Epoch  30 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 0.93 | Val Acc: 74.80%\n",
            "Epoch  40 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.91 | Val Acc: 74.80%\n",
            "Epoch  50 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 75.60%\n",
            "Epoch  60 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.76 | Val Acc: 76.40%\n",
            "Epoch  70 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.79 | Val Acc: 76.20%\n",
            "Epoch  80 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.85 | Val Acc: 76.20%\n",
            "Epoch  90 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.84 | Val Acc: 76.40%\n",
            "Epoch 100 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.86 | Val Acc: 75.20%\n",
            "Epoch 110 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 74.40%\n",
            "Epoch 120 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.88 | Val Acc: 74.00%\n",
            "Epoch 130 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.94 | Val Acc: 73.40%\n",
            "Epoch 140 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.00 | Val Acc: 73.00%\n",
            "Epoch 150 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.01 | Val Acc: 70.80%\n",
            "Epoch 160 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.01 | Val Acc: 72.60%\n",
            "Epoch 170 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 0.99 | Val Acc: 72.20%\n",
            "Epoch 180 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.00 | Val Acc: 72.20%\n",
            "Epoch 190 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.03 | Val Acc: 73.20%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 31.15s\n",
            "Testing took 0.06s\n",
            "GAT test accuracy: 78.40%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "Jw_vRUkF2qUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gat_pub_med_config = {\n",
        "    \"model_name\": \"GAT\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gat_pub_med = Experiment(data_pub_med, GAT, gat_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gat_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQTd2kTuxtXb",
        "outputId": "85e46683-4d1c-43fe-acff-fa421d1f45d6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GAT, dataset: PubMed).\n",
            "GAT(\n",
            "  (gat1): GATv2Conv(500, 16, heads=8)\n",
            "  (gat2): GATv2Conv(128, 3, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.105 | Train Acc:  33.33% | Val Loss: 1.09 | Val Acc: 38.80%\n",
            "Epoch  10 | Train Loss: 0.460 | Train Acc:  95.00% | Val Loss: 0.70 | Val Acc: 74.20%\n",
            "Epoch  20 | Train Loss: 0.128 | Train Acc:  98.33% | Val Loss: 0.58 | Val Acc: 76.60%\n",
            "Epoch  30 | Train Loss: 0.055 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 76.00%\n",
            "Epoch  40 | Train Loss: 0.042 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 76.40%\n",
            "Epoch  50 | Train Loss: 0.049 | Train Acc: 100.00% | Val Loss: 0.68 | Val Acc: 74.60%\n",
            "Epoch  60 | Train Loss: 0.046 | Train Acc: 100.00% | Val Loss: 0.64 | Val Acc: 76.00%\n",
            "Epoch  70 | Train Loss: 0.031 | Train Acc: 100.00% | Val Loss: 0.65 | Val Acc: 75.80%\n",
            "Epoch  80 | Train Loss: 0.030 | Train Acc: 100.00% | Val Loss: 0.70 | Val Acc: 73.60%\n",
            "Epoch  90 | Train Loss: 0.033 | Train Acc: 100.00% | Val Loss: 0.67 | Val Acc: 75.80%\n",
            "Epoch 100 | Train Loss: 0.031 | Train Acc: 100.00% | Val Loss: 0.72 | Val Acc: 73.40%\n",
            "Epoch 110 | Train Loss: 0.028 | Train Acc: 100.00% | Val Loss: 0.77 | Val Acc: 72.80%\n",
            "Epoch 120 | Train Loss: 0.026 | Train Acc: 100.00% | Val Loss: 0.77 | Val Acc: 73.00%\n",
            "Epoch 130 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.71 | Val Acc: 75.00%\n",
            "Epoch 140 | Train Loss: 0.024 | Train Acc: 100.00% | Val Loss: 0.71 | Val Acc: 75.60%\n",
            "Epoch 150 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 73.60%\n",
            "Epoch 160 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.75 | Val Acc: 75.40%\n",
            "Epoch 170 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.70 | Val Acc: 76.60%\n",
            "Epoch 180 | Train Loss: 0.023 | Train Acc: 100.00% | Val Loss: 0.73 | Val Acc: 76.60%\n",
            "Epoch 190 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.75 | Val Acc: 75.40%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 145.37s\n",
            "Testing took 0.27s\n",
            "GAT test accuracy: 76.70%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GATv2 Experiments"
      ],
      "metadata": {
        "id": "OUgEXyjA2waA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "n05pOWyi42pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gatv2_cite_seer_config = {\n",
        "    \"model_name\": \"GATv2\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gatv2_cite_seer = Experiment(data_cite_seer, GATv2, gatv2_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gatv2_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEY3zA4E45Uf",
        "outputId": "25eda885-0741-4938-cb37-ab1be1fe5560"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GATv2, dataset: CiteSeer).\n",
            "GATv2(\n",
            "  (gat1): GATv2Conv(3703, 16, heads=8)\n",
            "  (gat2): GATv2Conv(128, 6, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.818 | Train Acc:  13.33% | Val Loss: 1.80 | Val Acc: 15.40%\n",
            "Epoch  10 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.47 | Val Acc: 65.00%\n",
            "Epoch  20 | Train Loss: 0.000 | Train Acc: 100.00% | Val Loss: 1.63 | Val Acc: 63.00%\n",
            "Epoch  30 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 1.46 | Val Acc: 66.20%\n",
            "Epoch  40 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 1.33 | Val Acc: 66.60%\n",
            "Epoch  50 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.17 | Val Acc: 67.80%\n",
            "Epoch  60 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 70.80%\n",
            "Epoch  70 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.18 | Val Acc: 66.20%\n",
            "Epoch  80 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 68.60%\n",
            "Epoch  90 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 68.60%\n",
            "Epoch 100 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.17 | Val Acc: 68.40%\n",
            "Epoch 110 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.11 | Val Acc: 68.40%\n",
            "Epoch 120 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 1.17 | Val Acc: 67.60%\n",
            "Epoch 130 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.16 | Val Acc: 69.00%\n",
            "Epoch 140 | Train Loss: 0.011 | Train Acc:  99.17% | Val Loss: 1.14 | Val Acc: 67.80%\n",
            "Epoch 150 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 65.00%\n",
            "Epoch 160 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 1.30 | Val Acc: 66.40%\n",
            "Epoch 170 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 1.23 | Val Acc: 67.80%\n",
            "Epoch 180 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.20 | Val Acc: 68.80%\n",
            "Epoch 190 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.29 | Val Acc: 66.60%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 56.75s\n",
            "Testing took 0.12s\n",
            "GATv2 test accuracy: 65.60%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "sgbYu6Bq45vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gatv2_cora_config = {\n",
        "    \"model_name\": \"GATv2\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gatv2_cora = Experiment(data_cora, GATv2, gatv2_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gatv2_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEFH7kY747Zt",
        "outputId": "0b493332-31a9-4fd2-dc18-37b288a3054b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GATv2, dataset: Cora).\n",
            "GATv2(\n",
            "  (gat1): GATv2Conv(1433, 16, heads=8)\n",
            "  (gat2): GATv2Conv(128, 7, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.953 | Train Acc:  13.57% | Val Loss: 1.93 | Val Acc: 18.40%\n",
            "Epoch  10 | Train Loss: 0.022 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 74.60%\n",
            "Epoch  20 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 1.29 | Val Acc: 74.60%\n",
            "Epoch  30 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 1.22 | Val Acc: 74.00%\n",
            "Epoch  40 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.04 | Val Acc: 71.40%\n",
            "Epoch  50 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.94 | Val Acc: 73.80%\n",
            "Epoch  60 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.89 | Val Acc: 74.40%\n",
            "Epoch  70 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.85 | Val Acc: 74.60%\n",
            "Epoch  80 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.90 | Val Acc: 73.40%\n",
            "Epoch  90 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.90 | Val Acc: 74.60%\n",
            "Epoch 100 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.92 | Val Acc: 74.20%\n",
            "Epoch 110 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.91 | Val Acc: 74.80%\n",
            "Epoch 120 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.98 | Val Acc: 73.80%\n",
            "Epoch 130 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.92 | Val Acc: 75.00%\n",
            "Epoch 140 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.92 | Val Acc: 76.00%\n",
            "Epoch 150 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.94 | Val Acc: 74.60%\n",
            "Epoch 160 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.99 | Val Acc: 75.00%\n",
            "Epoch 170 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.98 | Val Acc: 74.40%\n",
            "Epoch 180 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.95 | Val Acc: 76.00%\n",
            "Epoch 190 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 0.99 | Val Acc: 74.00%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 25.47s\n",
            "Testing took 0.06s\n",
            "GATv2 test accuracy: 79.20%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "qih0nX5f477b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gatv2_pub_med_config = {\n",
        "    \"model_name\": \"GATv2\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gatv2_pub_med = Experiment(data_pub_med, GATv2, gatv2_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gatv2_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWjAxK134-Wt",
        "outputId": "37405193-d155-4d83-d3a8-4755cd2572ac"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GATv2, dataset: PubMed).\n",
            "GATv2(\n",
            "  (gat1): GATv2Conv(500, 16, heads=8)\n",
            "  (gat2): GATv2Conv(128, 3, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.099 | Train Acc:  33.33% | Val Loss: 1.12 | Val Acc: 21.40%\n",
            "Epoch  10 | Train Loss: 0.435 | Train Acc:  95.00% | Val Loss: 0.70 | Val Acc: 74.60%\n",
            "Epoch  20 | Train Loss: 0.137 | Train Acc:  95.00% | Val Loss: 0.56 | Val Acc: 78.40%\n",
            "Epoch  30 | Train Loss: 0.057 | Train Acc: 100.00% | Val Loss: 0.57 | Val Acc: 78.80%\n",
            "Epoch  40 | Train Loss: 0.054 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 77.80%\n",
            "Epoch  50 | Train Loss: 0.054 | Train Acc: 100.00% | Val Loss: 0.62 | Val Acc: 77.80%\n",
            "Epoch  60 | Train Loss: 0.047 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 77.20%\n",
            "Epoch  70 | Train Loss: 0.043 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 76.80%\n",
            "Epoch  80 | Train Loss: 0.029 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 77.40%\n",
            "Epoch  90 | Train Loss: 0.031 | Train Acc: 100.00% | Val Loss: 0.64 | Val Acc: 76.20%\n",
            "Epoch 100 | Train Loss: 0.024 | Train Acc: 100.00% | Val Loss: 0.65 | Val Acc: 78.00%\n",
            "Epoch 110 | Train Loss: 0.022 | Train Acc: 100.00% | Val Loss: 0.66 | Val Acc: 76.20%\n",
            "Epoch 120 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 76.00%\n",
            "Epoch 130 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.73 | Val Acc: 75.00%\n",
            "Epoch 140 | Train Loss: 0.020 | Train Acc: 100.00% | Val Loss: 0.63 | Val Acc: 77.00%\n",
            "Epoch 150 | Train Loss: 0.024 | Train Acc: 100.00% | Val Loss: 0.67 | Val Acc: 76.00%\n",
            "Epoch 160 | Train Loss: 0.019 | Train Acc: 100.00% | Val Loss: 0.64 | Val Acc: 75.80%\n",
            "Epoch 170 | Train Loss: 0.016 | Train Acc: 100.00% | Val Loss: 0.67 | Val Acc: 76.20%\n",
            "Epoch 180 | Train Loss: 0.016 | Train Acc: 100.00% | Val Loss: 0.66 | Val Acc: 77.60%\n",
            "Epoch 190 | Train Loss: 0.021 | Train Acc: 100.00% | Val Loss: 0.65 | Val Acc: 76.40%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 131.91s\n",
            "Testing took 0.27s\n",
            "GATv2 test accuracy: 75.80%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom L-CAT Experiments"
      ],
      "metadata": {
        "id": "ZhO_aFRZ6DX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "tswB9pNH6x59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcat_cite_seer_config = {\n",
        "    \"model_name\": \"L-Cat\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True\n",
        "}\n",
        "\n",
        "experiment_lcat_cite_seer = Experiment(data_cite_seer, LCATMy, lcat_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_lcat_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYq3pyF96zY5",
        "outputId": "fbfad1ad-5145-48f4-d424-f229003d306c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: L-Cat, dataset: CiteSeer).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(3703, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 6, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.814 | Train Acc:  10.00% | Val Loss: 1.81 | Val Acc: 9.60%\n",
            "Epoch  10 | Train Loss: 0.039 | Train Acc:  98.33% | Val Loss: 1.47 | Val Acc: 66.40%\n",
            "Epoch  20 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.69 | Val Acc: 65.40%\n",
            "Epoch  30 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 1.59 | Val Acc: 66.00%\n",
            "Epoch  40 | Train Loss: 0.030 | Train Acc:  98.33% | Val Loss: 1.45 | Val Acc: 65.00%\n",
            "Epoch  50 | Train Loss: 0.016 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 65.80%\n",
            "Epoch  60 | Train Loss: 0.018 | Train Acc:  99.17% | Val Loss: 1.37 | Val Acc: 66.00%\n",
            "Epoch  70 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.30 | Val Acc: 66.20%\n",
            "Epoch  80 | Train Loss: 0.025 | Train Acc:  98.33% | Val Loss: 1.32 | Val Acc: 66.60%\n",
            "Epoch  90 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.41 | Val Acc: 65.20%\n",
            "Epoch 100 | Train Loss: 0.020 | Train Acc:  99.17% | Val Loss: 1.36 | Val Acc: 66.80%\n",
            "Epoch 110 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 1.40 | Val Acc: 67.20%\n",
            "Epoch 120 | Train Loss: 0.016 | Train Acc:  99.17% | Val Loss: 1.36 | Val Acc: 67.00%\n",
            "Epoch 130 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.28 | Val Acc: 66.40%\n",
            "Epoch 140 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 67.20%\n",
            "Epoch 150 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 1.41 | Val Acc: 65.60%\n",
            "Epoch 160 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.39 | Val Acc: 67.00%\n",
            "Epoch 170 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.55 | Val Acc: 64.20%\n",
            "Epoch 180 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.37 | Val Acc: 67.20%\n",
            "Epoch 190 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.31 | Val Acc: 67.60%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 212.64s\n",
            "Testing took 0.84s\n",
            "L-Cat test accuracy: 66.60%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "d7HroMqa85_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcat_cora_config = {\n",
        "    \"model_name\": \"L-Cat\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True\n",
        "}\n",
        "\n",
        "experiment_lcat_cora = Experiment(data_cora, LCATMy, lcat_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_lcat_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DpzXzuw9Ba_",
        "outputId": "1fcb0c14-961d-488f-e4d3-d73b00491c41"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: L-Cat, dataset: Cora).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(1433, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 7, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.932 | Train Acc:  17.86% | Val Loss: 1.93 | Val Acc: 18.20%\n",
            "Epoch  10 | Train Loss: 0.022 | Train Acc: 100.00% | Val Loss: 0.73 | Val Acc: 77.60%\n",
            "Epoch  20 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 0.97 | Val Acc: 76.20%\n",
            "Epoch  30 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 0.97 | Val Acc: 76.40%\n",
            "Epoch  40 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 0.88 | Val Acc: 76.00%\n",
            "Epoch  50 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 76.80%\n",
            "Epoch  60 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 0.79 | Val Acc: 76.80%\n",
            "Epoch  70 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 76.80%\n",
            "Epoch  80 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 76.20%\n",
            "Epoch  90 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 74.80%\n",
            "Epoch 100 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.78 | Val Acc: 77.60%\n",
            "Epoch 110 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.79 | Val Acc: 77.40%\n",
            "Epoch 120 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 77.20%\n",
            "Epoch 130 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.78 | Val Acc: 77.00%\n",
            "Epoch 140 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.77 | Val Acc: 78.40%\n",
            "Epoch 150 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.77 | Val Acc: 77.40%\n",
            "Epoch 160 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.79 | Val Acc: 77.20%\n",
            "Epoch 170 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 76.60%\n",
            "Epoch 180 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.84 | Val Acc: 76.00%\n",
            "Epoch 190 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 77.20%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 84.45s\n",
            "Testing took 0.35s\n",
            "L-Cat test accuracy: 80.70%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "Jf0XTPFh9Q48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcat_pub_med_config = {\n",
        "    \"model_name\": \"L-Cat\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True\n",
        "}\n",
        "\n",
        "experiment_lcat_pub_med = Experiment(data_pub_med, LCATMy, lcat_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_lcat_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DvKWnfs6Hkw",
        "outputId": "3de79994-35c5-4fb9-f85a-3a1a49fca503"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: L-Cat, dataset: PubMed).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(500, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 3, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.098 | Train Acc:  30.00% | Val Loss: 1.10 | Val Acc: 33.60%\n",
            "Epoch  10 | Train Loss: 0.432 | Train Acc:  93.33% | Val Loss: 0.68 | Val Acc: 74.80%\n",
            "Epoch  20 | Train Loss: 0.136 | Train Acc:  96.67% | Val Loss: 0.56 | Val Acc: 77.00%\n",
            "Epoch  30 | Train Loss: 0.060 | Train Acc: 100.00% | Val Loss: 0.57 | Val Acc: 78.60%\n",
            "Epoch  40 | Train Loss: 0.058 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.00%\n",
            "Epoch  50 | Train Loss: 0.056 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 77.80%\n",
            "Epoch  60 | Train Loss: 0.052 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 77.60%\n",
            "Epoch  70 | Train Loss: 0.048 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 77.80%\n",
            "Epoch  80 | Train Loss: 0.039 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 77.60%\n",
            "Epoch  90 | Train Loss: 0.041 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 77.60%\n",
            "Epoch 100 | Train Loss: 0.037 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 76.80%\n",
            "Epoch 110 | Train Loss: 0.037 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 76.80%\n",
            "Epoch 120 | Train Loss: 0.033 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 76.80%\n",
            "Epoch 130 | Train Loss: 0.034 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 77.00%\n",
            "Epoch 140 | Train Loss: 0.035 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 77.00%\n",
            "Epoch 150 | Train Loss: 0.030 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 77.40%\n",
            "Epoch 160 | Train Loss: 0.029 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 77.00%\n",
            "Epoch 170 | Train Loss: 0.031 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 77.40%\n",
            "Epoch 180 | Train Loss: 0.028 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 77.60%\n",
            "Epoch 190 | Train Loss: 0.025 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 76.60%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 1831.32s\n",
            "Testing took 7.19s\n",
            "L-Cat test accuracy: 77.10%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CAT Experiments"
      ],
      "metadata": {
        "id": "OqDBhQnbdA8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "zv0rlXK0fXbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cite_seer_config = {\n",
        "    \"model_name\": \"CAT\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True,\n",
        "    \"hardcoded_lambdas\": (1, 1) # by the statement of the paper and by the design of the layer L-Cat with thse lambdas will be CAT\n",
        "}\n",
        "\n",
        "experiment_cat_cite_seer = Experiment(data_cite_seer, LCATMy, cat_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_cat_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE-JEUiefV0p",
        "outputId": "d934605e-00b3-4d1c-8d93-2e0af2b8969f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yeees\n",
            "Finished experiment initialization (model: Cat, dataset: CiteSeer).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(3703, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 6, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.803 | Train Acc:  19.17% | Val Loss: 1.81 | Val Acc: 12.00%\n",
            "Epoch  10 | Train Loss: 0.046 | Train Acc:  97.50% | Val Loss: 1.47 | Val Acc: 65.40%\n",
            "Epoch  20 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 1.68 | Val Acc: 65.40%\n",
            "Epoch  30 | Train Loss: 0.028 | Train Acc:  99.17% | Val Loss: 1.57 | Val Acc: 66.40%\n",
            "Epoch  40 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 1.38 | Val Acc: 65.80%\n",
            "Epoch  50 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 1.27 | Val Acc: 66.20%\n",
            "Epoch  60 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.26 | Val Acc: 67.40%\n",
            "Epoch  70 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.26 | Val Acc: 68.00%\n",
            "Epoch  80 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.22 | Val Acc: 68.20%\n",
            "Epoch  90 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.27 | Val Acc: 68.00%\n",
            "Epoch 100 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.21 | Val Acc: 69.00%\n",
            "Epoch 110 | Train Loss: 0.023 | Train Acc:  99.17% | Val Loss: 1.27 | Val Acc: 67.00%\n",
            "Epoch 120 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.29 | Val Acc: 67.40%\n",
            "Epoch 130 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.38 | Val Acc: 68.00%\n",
            "Epoch 140 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.26 | Val Acc: 68.20%\n",
            "Epoch 150 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.30 | Val Acc: 68.00%\n",
            "Epoch 160 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.28 | Val Acc: 68.60%\n",
            "Epoch 170 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.33 | Val Acc: 67.20%\n",
            "Epoch 180 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 67.40%\n",
            "Epoch 190 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.35 | Val Acc: 68.60%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 184.08s\n",
            "Testing took 0.79s\n",
            "Cat test accuracy: 67.10%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "PRwiwA9OihKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cora_config = {\n",
        "    \"model_name\": \"CAT\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True,\n",
        "    \"hardcoded_lambdas\": (1, 1)\n",
        "}\n",
        "\n",
        "experiment_cat_cora = Experiment(data_cora, LCATMy, cat_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_cat_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbGVLDmsiiOf",
        "outputId": "1708e8b8-614e-4cf8-b28c-a5ed29e48133"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: Cat, dataset: Cora).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(1433, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 7, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.963 | Train Acc:   9.29% | Val Loss: 1.99 | Val Acc: 6.00%\n",
            "Epoch  10 | Train Loss: 0.040 | Train Acc:  99.29% | Val Loss: 0.68 | Val Acc: 80.40%\n",
            "Epoch  20 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.88 | Val Acc: 79.00%\n",
            "Epoch  30 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.95 | Val Acc: 77.20%\n",
            "Epoch  40 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.84 | Val Acc: 78.40%\n",
            "Epoch  50 | Train Loss: 0.012 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 76.40%\n",
            "Epoch  60 | Train Loss: 0.014 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 77.40%\n",
            "Epoch  70 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 0.88 | Val Acc: 76.80%\n",
            "Epoch  80 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 77.40%\n",
            "Epoch  90 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 76.40%\n",
            "Epoch 100 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.84 | Val Acc: 76.40%\n",
            "Epoch 110 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.86 | Val Acc: 77.40%\n",
            "Epoch 120 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 77.00%\n",
            "Epoch 130 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 76.80%\n",
            "Epoch 140 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.88 | Val Acc: 76.80%\n",
            "Epoch 150 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 76.20%\n",
            "Epoch 160 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.91 | Val Acc: 76.20%\n",
            "Epoch 170 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.86 | Val Acc: 77.00%\n",
            "Epoch 180 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.90 | Val Acc: 75.80%\n",
            "Epoch 190 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.91 | Val Acc: 75.80%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 72.09s\n",
            "Testing took 0.26s\n",
            "Cat test accuracy: 79.40%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "CwP6HVfAiz-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_pub_med_config = {\n",
        "    \"model_name\": \"CAT\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True,\n",
        "    \"hardcoded_lambdas\": (1, 1)\n",
        "}\n",
        "\n",
        "experiment_cat_pub_med = Experiment(data_pub_med, LCATMy, cat_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_cat_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZoP-g3Xi2i3",
        "outputId": "24c6bf68-0b58-4610-cd69-ded46ad5446b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: CAT, dataset: PubMed).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(500, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 3, heads=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global L-CAT Experimnts"
      ],
      "metadata": {
        "id": "TaXfsmkatMRF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "YVvq0oSctP_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcat_global_cite_seer_config = {\n",
        "    \"model_name\": \"L-Cat\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True,\n",
        "    \"global_lambdas\": True\n",
        "}\n",
        "\n",
        "experiment_lcat_global_cite_seer = Experiment(data_cite_seer, LCATMy, lcat_global_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_lcat_global_cite_seer.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Co8FIltRKW",
        "outputId": "3c36c898-cbb8-435f-ab54-47c8dd62dcd6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: L-Cat, dataset: CiteSeer).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(3703, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 6, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.799 | Train Acc:  17.50% | Val Loss: 1.79 | Val Acc: 19.60%\n",
            "Epoch  10 | Train Loss: 0.057 | Train Acc:  97.50% | Val Loss: 1.49 | Val Acc: 65.00%\n",
            "Epoch  20 | Train Loss: 0.028 | Train Acc:  99.17% | Val Loss: 1.53 | Val Acc: 66.20%\n",
            "Epoch  30 | Train Loss: 0.010 | Train Acc:  99.17% | Val Loss: 1.40 | Val Acc: 67.40%\n",
            "Epoch  40 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 1.26 | Val Acc: 68.20%\n",
            "Epoch  50 | Train Loss: 0.013 | Train Acc:  99.17% | Val Loss: 1.20 | Val Acc: 68.60%\n",
            "Epoch  60 | Train Loss: 0.010 | Train Acc: 100.00% | Val Loss: 1.27 | Val Acc: 65.20%\n",
            "Epoch  70 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.23 | Val Acc: 65.80%\n",
            "Epoch  80 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.23 | Val Acc: 66.80%\n",
            "Epoch  90 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.20 | Val Acc: 67.80%\n",
            "Epoch 100 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.21 | Val Acc: 65.80%\n",
            "Epoch 110 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.21 | Val Acc: 66.60%\n",
            "Epoch 120 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.25 | Val Acc: 65.80%\n",
            "Epoch 130 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.29 | Val Acc: 67.20%\n",
            "Epoch 140 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 1.31 | Val Acc: 66.80%\n",
            "Epoch 150 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.30 | Val Acc: 66.40%\n",
            "Epoch 160 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.27 | Val Acc: 65.80%\n",
            "Epoch 170 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.38 | Val Acc: 65.20%\n",
            "Epoch 180 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.46 | Val Acc: 64.00%\n",
            "Epoch 190 | Train Loss: 0.022 | Train Acc:  99.17% | Val Loss: 1.46 | Val Acc: 65.60%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 212.29s\n",
            "Testing took 0.79s\n",
            "L-Cat test accuracy: 67.00%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "tFHLEx7TzKLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcat_global_cora_config = {\n",
        "    \"model_name\": \"L-Cat\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True,\n",
        "    \"global_lambdas\": True\n",
        "}\n",
        "\n",
        "experiment_lcat_global_cora = Experiment(data_cora, LCATMy, lcat_global_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_lcat_global_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ5kdzXNzL2o",
        "outputId": "fbc37555-dbe3-40fa-cdaa-5fd2a18405d1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: L-Cat, dataset: Cora).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(1433, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 7, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.937 | Train Acc:  22.86% | Val Loss: 1.94 | Val Acc: 17.20%\n",
            "Epoch  10 | Train Loss: 0.042 | Train Acc:  99.29% | Val Loss: 0.74 | Val Acc: 78.60%\n",
            "Epoch  20 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.00 | Val Acc: 77.00%\n",
            "Epoch  30 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.08 | Val Acc: 76.80%\n",
            "Epoch  40 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.93 | Val Acc: 76.60%\n",
            "Epoch  50 | Train Loss: 0.011 | Train Acc: 100.00% | Val Loss: 0.85 | Val Acc: 76.80%\n",
            "Epoch  60 | Train Loss: 0.013 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 76.80%\n",
            "Epoch  70 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.89 | Val Acc: 76.80%\n",
            "Epoch  80 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.87 | Val Acc: 76.40%\n",
            "Epoch  90 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.89 | Val Acc: 77.60%\n",
            "Epoch 100 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.92 | Val Acc: 75.80%\n",
            "Epoch 110 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.89 | Val Acc: 76.00%\n",
            "Epoch 120 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.88 | Val Acc: 76.80%\n",
            "Epoch 130 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.93 | Val Acc: 76.80%\n",
            "Epoch 140 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.90 | Val Acc: 77.00%\n",
            "Epoch 150 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.95 | Val Acc: 76.80%\n",
            "Epoch 160 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.95 | Val Acc: 76.20%\n",
            "Epoch 170 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.91 | Val Acc: 76.80%\n",
            "Epoch 180 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.96 | Val Acc: 75.80%\n",
            "Epoch 190 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.99 | Val Acc: 75.00%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 78.74s\n",
            "Testing took 0.28s\n",
            "L-Cat test accuracy: 79.40%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "K0SPOnHAzYzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lcat_global_pub_med_config = {\n",
        "    \"model_name\": \"L-Cat\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": True,\n",
        "    \"global_lambdas\": True\n",
        "}\n",
        "\n",
        "experiment_lcat_global_pub_med = Experiment(data_pub_med, LCATMy, lcat_global_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_lcat_global_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHPvxusIzaga",
        "outputId": "e550361d-049a-4a6f-db02-59d092581a72"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: L-Cat, dataset: PubMed).\n",
            "LCATMy(\n",
            "  (gat1): LCATLayerMy(500, 16, heads=8)\n",
            "  (gat2): LCATLayerMy(128, 3, heads=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN+GAT Experiments"
      ],
      "metadata": {
        "id": "c1lwhd5SXitf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CireSeer"
      ],
      "metadata": {
        "id": "G6ysBMQ9XoqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_gat_cite_seer_config = {\n",
        "    \"model_name\": \"GCN_GAT\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gcn_gat_cite_seer = Experiment(data_cite_seer, GCN_GAT, gcn_gat_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_gat_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXeOYqp2XqSK",
        "outputId": "533acdd9-fc42-4a33-8277-930946b8d187"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GCN_GAT, dataset: CiteSeer).\n",
            "GCN_GAT(\n",
            "  (gcn1): GCNConv(3703, 16)\n",
            "  (gat2): GATConv(16, 6, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.795 | Train Acc:  10.00% | Val Loss: 1.80 | Val Acc: 14.40%\n",
            "Epoch  10 | Train Loss: 0.439 | Train Acc:  88.33% | Val Loss: 1.25 | Val Acc: 59.00%\n",
            "Epoch  20 | Train Loss: 0.150 | Train Acc:  97.50% | Val Loss: 1.41 | Val Acc: 56.00%\n",
            "Epoch  30 | Train Loss: 0.117 | Train Acc:  97.50% | Val Loss: 1.22 | Val Acc: 60.60%\n",
            "Epoch  40 | Train Loss: 0.067 | Train Acc:  98.33% | Val Loss: 1.45 | Val Acc: 57.40%\n",
            "Epoch  50 | Train Loss: 0.072 | Train Acc:  99.17% | Val Loss: 1.37 | Val Acc: 60.60%\n",
            "Epoch  60 | Train Loss: 0.063 | Train Acc:  99.17% | Val Loss: 1.47 | Val Acc: 61.80%\n",
            "Epoch  70 | Train Loss: 0.053 | Train Acc: 100.00% | Val Loss: 1.35 | Val Acc: 60.80%\n",
            "Epoch  80 | Train Loss: 0.054 | Train Acc:  99.17% | Val Loss: 1.51 | Val Acc: 57.00%\n",
            "Epoch  90 | Train Loss: 0.056 | Train Acc:  98.33% | Val Loss: 1.37 | Val Acc: 61.80%\n",
            "Epoch 100 | Train Loss: 0.046 | Train Acc:  99.17% | Val Loss: 1.57 | Val Acc: 61.00%\n",
            "Epoch 110 | Train Loss: 0.050 | Train Acc:  99.17% | Val Loss: 1.38 | Val Acc: 61.60%\n",
            "Epoch 120 | Train Loss: 0.049 | Train Acc: 100.00% | Val Loss: 1.43 | Val Acc: 62.20%\n",
            "Epoch 130 | Train Loss: 0.025 | Train Acc: 100.00% | Val Loss: 1.36 | Val Acc: 64.20%\n",
            "Epoch 140 | Train Loss: 0.028 | Train Acc:  99.17% | Val Loss: 1.42 | Val Acc: 60.60%\n",
            "Epoch 150 | Train Loss: 0.063 | Train Acc:  99.17% | Val Loss: 1.32 | Val Acc: 63.40%\n",
            "Epoch 160 | Train Loss: 0.045 | Train Acc: 100.00% | Val Loss: 1.42 | Val Acc: 62.20%\n",
            "Epoch 170 | Train Loss: 0.017 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 63.60%\n",
            "Epoch 180 | Train Loss: 0.039 | Train Acc:  99.17% | Val Loss: 1.41 | Val Acc: 63.60%\n",
            "Epoch 190 | Train Loss: 0.036 | Train Acc:  99.17% | Val Loss: 1.41 | Val Acc: 67.20%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 7.12s\n",
            "Testing took 0.01s\n",
            "GCN_GAT test accuracy: 68.40%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "9M_BWeO9YQq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_gat_cora_config = {\n",
        "    \"model_name\": \"GCN_GAT\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gcn_gat_cora = Experiment(data_cora, GCN_GAT, gcn_gat_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_gat_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up9bLutlYSFy",
        "outputId": "103d5a91-6598-4df7-855f-a2929a5beacf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GCN_GAT, dataset: Cora).\n",
            "GCN_GAT(\n",
            "  (gcn1): GCNConv(1433, 16)\n",
            "  (gat2): GATConv(16, 7, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.949 | Train Acc:  17.14% | Val Loss: 1.93 | Val Acc: 23.40%\n",
            "Epoch  10 | Train Loss: 0.850 | Train Acc:  90.71% | Val Loss: 1.26 | Val Acc: 66.80%\n",
            "Epoch  20 | Train Loss: 0.340 | Train Acc:  95.71% | Val Loss: 1.19 | Val Acc: 67.40%\n",
            "Epoch  30 | Train Loss: 0.220 | Train Acc:  95.00% | Val Loss: 1.18 | Val Acc: 65.60%\n",
            "Epoch  40 | Train Loss: 0.166 | Train Acc:  98.57% | Val Loss: 1.13 | Val Acc: 69.20%\n",
            "Epoch  50 | Train Loss: 0.101 | Train Acc:  99.29% | Val Loss: 1.17 | Val Acc: 70.00%\n",
            "Epoch  60 | Train Loss: 0.066 | Train Acc:  99.29% | Val Loss: 1.16 | Val Acc: 70.20%\n",
            "Epoch  70 | Train Loss: 0.059 | Train Acc:  99.29% | Val Loss: 1.30 | Val Acc: 69.40%\n",
            "Epoch  80 | Train Loss: 0.055 | Train Acc:  99.29% | Val Loss: 1.21 | Val Acc: 71.00%\n",
            "Epoch  90 | Train Loss: 0.054 | Train Acc: 100.00% | Val Loss: 1.32 | Val Acc: 68.60%\n",
            "Epoch 100 | Train Loss: 0.047 | Train Acc: 100.00% | Val Loss: 1.22 | Val Acc: 68.60%\n",
            "Epoch 110 | Train Loss: 0.050 | Train Acc:  99.29% | Val Loss: 1.28 | Val Acc: 70.20%\n",
            "Epoch 120 | Train Loss: 0.053 | Train Acc:  98.57% | Val Loss: 1.13 | Val Acc: 70.00%\n",
            "Epoch 130 | Train Loss: 0.043 | Train Acc:  99.29% | Val Loss: 1.21 | Val Acc: 70.00%\n",
            "Epoch 140 | Train Loss: 0.045 | Train Acc:  99.29% | Val Loss: 1.30 | Val Acc: 70.20%\n",
            "Epoch 150 | Train Loss: 0.041 | Train Acc: 100.00% | Val Loss: 1.51 | Val Acc: 70.60%\n",
            "Epoch 160 | Train Loss: 0.045 | Train Acc:  99.29% | Val Loss: 1.30 | Val Acc: 69.60%\n",
            "Epoch 170 | Train Loss: 0.029 | Train Acc: 100.00% | Val Loss: 1.28 | Val Acc: 71.60%\n",
            "Epoch 180 | Train Loss: 0.026 | Train Acc: 100.00% | Val Loss: 1.33 | Val Acc: 71.40%\n",
            "Epoch 190 | Train Loss: 0.033 | Train Acc:  99.29% | Val Loss: 1.29 | Val Acc: 69.60%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 4.24s\n",
            "Testing took 0.01s\n",
            "GCN_GAT test accuracy: 75.90%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "Pe_07CmvYQxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_gat_pub_med_config = {\n",
        "    \"model_name\": \"GCN_GAT\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gcn_gat_pub_med = Experiment(data_pub_med, GCN_GAT, gcn_gat_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gcn_gat_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAp_wt-3X5yB",
        "outputId": "09ea15d1-f925-4f14-a341-e30ca4fc7adf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GCN_GAT, dataset: PubMed).\n",
            "GCN_GAT(\n",
            "  (gcn1): GCNConv(500, 16)\n",
            "  (gat2): GATConv(16, 3, heads=1)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.100 | Train Acc:  26.67% | Val Loss: 1.10 | Val Acc: 40.60%\n",
            "Epoch  10 | Train Loss: 0.915 | Train Acc:  83.33% | Val Loss: 0.96 | Val Acc: 66.80%\n",
            "Epoch  20 | Train Loss: 0.682 | Train Acc:  91.67% | Val Loss: 0.77 | Val Acc: 70.60%\n",
            "Epoch  30 | Train Loss: 0.446 | Train Acc:  95.00% | Val Loss: 0.71 | Val Acc: 70.80%\n",
            "Epoch  40 | Train Loss: 0.357 | Train Acc:  91.67% | Val Loss: 0.69 | Val Acc: 72.60%\n",
            "Epoch  50 | Train Loss: 0.254 | Train Acc:  93.33% | Val Loss: 0.64 | Val Acc: 73.80%\n",
            "Epoch  60 | Train Loss: 0.207 | Train Acc:  96.67% | Val Loss: 0.68 | Val Acc: 74.80%\n",
            "Epoch  70 | Train Loss: 0.180 | Train Acc:  96.67% | Val Loss: 0.66 | Val Acc: 74.00%\n",
            "Epoch  80 | Train Loss: 0.113 | Train Acc: 100.00% | Val Loss: 0.68 | Val Acc: 72.20%\n",
            "Epoch  90 | Train Loss: 0.140 | Train Acc:  98.33% | Val Loss: 0.71 | Val Acc: 72.00%\n",
            "Epoch 100 | Train Loss: 0.100 | Train Acc: 100.00% | Val Loss: 0.73 | Val Acc: 72.40%\n",
            "Epoch 110 | Train Loss: 0.108 | Train Acc: 100.00% | Val Loss: 0.69 | Val Acc: 72.60%\n",
            "Epoch 120 | Train Loss: 0.099 | Train Acc: 100.00% | Val Loss: 0.72 | Val Acc: 72.80%\n",
            "Epoch 130 | Train Loss: 0.078 | Train Acc: 100.00% | Val Loss: 0.74 | Val Acc: 72.20%\n",
            "Epoch 140 | Train Loss: 0.073 | Train Acc: 100.00% | Val Loss: 0.74 | Val Acc: 73.20%\n",
            "Epoch 150 | Train Loss: 0.109 | Train Acc: 100.00% | Val Loss: 0.69 | Val Acc: 74.80%\n",
            "Epoch 160 | Train Loss: 0.074 | Train Acc: 100.00% | Val Loss: 0.77 | Val Acc: 75.20%\n",
            "Epoch 170 | Train Loss: 0.072 | Train Acc: 100.00% | Val Loss: 0.76 | Val Acc: 72.40%\n",
            "Epoch 180 | Train Loss: 0.073 | Train Acc: 100.00% | Val Loss: 0.69 | Val Acc: 74.60%\n",
            "Epoch 190 | Train Loss: 0.058 | Train Acc: 100.00% | Val Loss: 0.74 | Val Acc: 74.80%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 20.69s\n",
            "Testing took 0.04s\n",
            "GCN_GAT test accuracy: 72.30%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT + GCN Experiments"
      ],
      "metadata": {
        "id": "laY6C8sHbNV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CiteSeer"
      ],
      "metadata": {
        "id": "kK7ExZZGbXmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gat_gcn_cite_seer_config = {\n",
        "    \"model_name\": \"GAT_GCN\",\n",
        "    \"dataset_name\": \"CiteSeer\",\n",
        "    \"input_dimension\": dataset_cite_seer.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cite_seer.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gat_gcn_cite_seer = Experiment(data_cite_seer, GAT_GCN, gat_gcn_cite_seer_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gat_gcn_cite_seer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5mHCj9HbQRs",
        "outputId": "c937b484-4b75-435d-dc52-14413be02310"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GAT_GCN, dataset: CiteSeer).\n",
            "GAT_GCN(\n",
            "  (gat1): GATConv(3703, 16, heads=8)\n",
            "  (gcn2): GCNConv(128, 6)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.793 | Train Acc:  19.17% | Val Loss: 1.81 | Val Acc: 16.00%\n",
            "Epoch  10 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.25 | Val Acc: 67.20%\n",
            "Epoch  20 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 1.46 | Val Acc: 66.40%\n",
            "Epoch  30 | Train Loss: 0.002 | Train Acc: 100.00% | Val Loss: 1.36 | Val Acc: 67.60%\n",
            "Epoch  40 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.18 | Val Acc: 67.80%\n",
            "Epoch  50 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.13 | Val Acc: 67.80%\n",
            "Epoch  60 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.12 | Val Acc: 67.80%\n",
            "Epoch  70 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.13 | Val Acc: 68.00%\n",
            "Epoch  80 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.09 | Val Acc: 69.60%\n",
            "Epoch  90 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.10 | Val Acc: 69.00%\n",
            "Epoch 100 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.07 | Val Acc: 68.40%\n",
            "Epoch 110 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.14 | Val Acc: 67.60%\n",
            "Epoch 120 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.11 | Val Acc: 69.40%\n",
            "Epoch 130 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.09 | Val Acc: 67.60%\n",
            "Epoch 140 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 1.09 | Val Acc: 68.00%\n",
            "Epoch 150 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 1.07 | Val Acc: 71.20%\n",
            "Epoch 160 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.09 | Val Acc: 68.40%\n",
            "Epoch 170 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 1.11 | Val Acc: 68.00%\n",
            "Epoch 180 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.25 | Val Acc: 65.80%\n",
            "Epoch 190 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 1.22 | Val Acc: 67.80%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 26.19s\n",
            "Testing took 0.05s\n",
            "GAT_GCN test accuracy: 67.70%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora"
      ],
      "metadata": {
        "id": "CRGkwdJbbbwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gat_gcn_cora_config = {\n",
        "    \"model_name\": \"GAT_GCN\",\n",
        "    \"dataset_name\": \"Cora\",\n",
        "    \"input_dimension\": dataset_cora.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_cora.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gat_gcn_cora = Experiment(data_cora, GAT_GCN, gat_gcn_cora_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gat_gcn_cora.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvdRHhNDbdXR",
        "outputId": "d4a154bc-9ec2-4064-fa4b-45e4006ea786"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GAT_GCN, dataset: Cora).\n",
            "GAT_GCN(\n",
            "  (gat1): GATConv(1433, 16, heads=8)\n",
            "  (gcn2): GCNConv(128, 7)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.991 | Train Acc:   9.29% | Val Loss: 1.96 | Val Acc: 13.20%\n",
            "Epoch  10 | Train Loss: 0.025 | Train Acc:  99.29% | Val Loss: 0.79 | Val Acc: 77.60%\n",
            "Epoch  20 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 0.97 | Val Acc: 76.60%\n",
            "Epoch  30 | Train Loss: 0.001 | Train Acc: 100.00% | Val Loss: 1.04 | Val Acc: 76.00%\n",
            "Epoch  40 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 0.90 | Val Acc: 75.80%\n",
            "Epoch  50 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 77.20%\n",
            "Epoch  60 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.79 | Val Acc: 76.40%\n",
            "Epoch  70 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 77.80%\n",
            "Epoch  80 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 76.80%\n",
            "Epoch  90 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 76.80%\n",
            "Epoch 100 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 77.00%\n",
            "Epoch 110 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 76.80%\n",
            "Epoch 120 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 75.60%\n",
            "Epoch 130 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 76.60%\n",
            "Epoch 140 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 75.40%\n",
            "Epoch 150 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 75.40%\n",
            "Epoch 160 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.82 | Val Acc: 75.00%\n",
            "Epoch 170 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 74.60%\n",
            "Epoch 180 | Train Loss: 0.005 | Train Acc: 100.00% | Val Loss: 0.80 | Val Acc: 75.80%\n",
            "Epoch 190 | Train Loss: 0.006 | Train Acc: 100.00% | Val Loss: 0.81 | Val Acc: 75.40%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 13.92s\n",
            "Testing took 0.03s\n",
            "GAT_GCN test accuracy: 78.90%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PubMed"
      ],
      "metadata": {
        "id": "xv5svclgbd8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gat_gcn_pub_med_config = {\n",
        "    \"model_name\": \"GAT_GCN\",\n",
        "    \"dataset_name\": \"PubMed\",\n",
        "    \"input_dimension\": dataset_pub_med.num_features,\n",
        "    \"hidden_dimension\": 16,\n",
        "    \"output_dimension\": dataset_pub_med.num_classes,\n",
        "    \"num_heads\": 8,\n",
        "    \"loss\": torch.nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": torch.optim.Adam,\n",
        "    \"learning_rate\": 0.01,\n",
        "    \"weight_decay\": 5e-4,\n",
        "    \"num_epochs\": 200,\n",
        "    \"report_freq\": 10,\n",
        "    \"req_edge_index\": True,\n",
        "    \"req_adj_matrix\": False\n",
        "}\n",
        "\n",
        "experiment_gat_gcn_pub_med = Experiment(data_pub_med, GAT_GCN, gat_gcn_pub_med_config)\n",
        "\n",
        "accuracy, training_time, testing_time = experiment_gat_gcn_pub_med.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nonmnYqGbaPF",
        "outputId": "4f414eda-4fe0-4a18-a37f-ea151e05fc54"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished experiment initialization (model: GAT_GCN, dataset: PubMed).\n",
            "GAT_GCN(\n",
            "  (gat1): GATConv(500, 16, heads=8)\n",
            "  (gcn2): GCNConv(128, 3)\n",
            ")\n",
            "Started model training.\n",
            "Epoch   0 | Train Loss: 1.100 | Train Acc:  33.33% | Val Loss: 1.10 | Val Acc: 40.20%\n",
            "Epoch  10 | Train Loss: 0.518 | Train Acc:  96.67% | Val Loss: 0.75 | Val Acc: 75.00%\n",
            "Epoch  20 | Train Loss: 0.178 | Train Acc:  96.67% | Val Loss: 0.59 | Val Acc: 77.80%\n",
            "Epoch  30 | Train Loss: 0.085 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 78.20%\n",
            "Epoch  40 | Train Loss: 0.069 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 78.60%\n",
            "Epoch  50 | Train Loss: 0.064 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 78.20%\n",
            "Epoch  60 | Train Loss: 0.060 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 78.60%\n",
            "Epoch  70 | Train Loss: 0.050 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 78.00%\n",
            "Epoch  80 | Train Loss: 0.044 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.40%\n",
            "Epoch  90 | Train Loss: 0.044 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.20%\n",
            "Epoch 100 | Train Loss: 0.042 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.20%\n",
            "Epoch 110 | Train Loss: 0.036 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 79.00%\n",
            "Epoch 120 | Train Loss: 0.040 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.60%\n",
            "Epoch 130 | Train Loss: 0.032 | Train Acc: 100.00% | Val Loss: 0.61 | Val Acc: 78.40%\n",
            "Epoch 140 | Train Loss: 0.032 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.80%\n",
            "Epoch 150 | Train Loss: 0.034 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 78.60%\n",
            "Epoch 160 | Train Loss: 0.031 | Train Acc: 100.00% | Val Loss: 0.59 | Val Acc: 80.20%\n",
            "Epoch 170 | Train Loss: 0.031 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 79.60%\n",
            "Epoch 180 | Train Loss: 0.025 | Train Acc: 100.00% | Val Loss: 0.58 | Val Acc: 79.20%\n",
            "Epoch 190 | Train Loss: 0.025 | Train Acc: 100.00% | Val Loss: 0.60 | Val Acc: 79.40%\n",
            "Finished model training.\n",
            "Started model testing.\n",
            "Finished model testing.\n",
            "Training took 76.19s\n",
            "Testing took 0.15s\n",
            "GAT_GCN test accuracy: 78.20%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIpI4bSQZBeo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}